{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, classification_report,mean_squared_error, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the dataset which comes from short_dataset_feature_engineering.ipynb \n",
    "file_path = '/data/caysar9/results/final_short.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency counts before SMOTE:\n",
      "Frequency counts train set\n",
      "next_migraine_next_day\n",
      "0    10354\n",
      "1     1167\n",
      "Name: count, dtype: int64\n",
      "Frequency counts test set\n",
      "next_migraine_next_day\n",
      "0    2589\n",
      "1     292\n",
      "Name: count, dtype: int64\n",
      "Frequency counts after SMOTE:\n",
      "Frequency counts train set\n",
      "next_migraine_next_day\n",
      "0    10354\n",
      "1    10354\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# predicting the next migraine in the next day\n",
    "\n",
    "features = ['trigger_lack_physical_activity','trigger_physical_activity','trigger_poor_sleep','trigger_stress','sleep_duration_hours','sleep_duration_past_7_days','age','migraine_attacks_past7days','mean_migraine_duration_past7days','total_physical_activity','reported_anxiety', 'reported_depression']\n",
    "\n",
    "target = 'next_migraine_next_day'  \n",
    "\n",
    "X = df[features]\n",
    "\n",
    "y = df[target]\n",
    "  \n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Frequency counts before applying SMOTE\n",
    "print(\"Frequency counts before SMOTE:\")\n",
    "print(\"Frequency counts train set\")\n",
    "print(y_train.value_counts())\n",
    "print(\"Frequency counts test set\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "# Frequency counts before applying SMOTE\n",
    "print(\"Frequency counts after SMOTE:\")\n",
    "print(\"Frequency counts train set\")\n",
    "print(y_train_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "36 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1204, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.71512177 0.71042721\n",
      " 0.71855579 0.71611963 0.71699855        nan 0.71855495        nan\n",
      " 0.71494925 0.71516756        nan 0.71854949 0.71718154 0.71854958\n",
      " 0.71687007        nan        nan 0.71464357 0.71719917 0.71854846\n",
      " 0.71854507 0.71516182        nan        nan        nan 0.71238305]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 6.126531604882809, 'max_iter': 352, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n",
      "AUC Score: 0.5606\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1334 1255]\n",
      " [ 127  165]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.52      0.66      2589\n",
      "           1       0.12      0.57      0.19       292\n",
      "\n",
      "    accuracy                           0.52      2881\n",
      "   macro avg       0.51      0.54      0.43      2881\n",
      "weighted avg       0.83      0.52      0.61      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],  # Regularization methods\n",
    "    'C': uniform(0.01, 10),  # Continuous uniform distribution for regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # solvers\n",
    "    'max_iter': randint(100, 1000)  # Randomly sample number of iterations\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,  # Number of random combinations to try\n",
    "    scoring='roc_auc',  # Evaluate based on AUC\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the best model on the balanced training set\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Calculate and display AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.613602\n",
      "         Iterations 7\n",
      "                             Logit Regression Results                             \n",
      "==================================================================================\n",
      "Dep. Variable:     next_migraine_next_day   No. Observations:                20708\n",
      "Model:                              Logit   Df Residuals:                    20695\n",
      "Method:                               MLE   Df Model:                           12\n",
      "Date:                    Sat, 07 Dec 2024   Pseudo R-squ.:                  0.1148\n",
      "Time:                            20:01:28   Log-Likelihood:                -12706.\n",
      "converged:                           True   LL-Null:                       -14354.\n",
      "Covariance Type:                nonrobust   LLR p-value:                     0.000\n",
      "====================================================================================================\n",
      "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "const                                0.2726      0.099      2.760      0.006       0.079       0.466\n",
      "trigger_lack_physical_activity      -1.3616      0.100    -13.630      0.000      -1.557      -1.166\n",
      "trigger_physical_activity           -1.9646      0.239     -8.226      0.000      -2.433      -1.497\n",
      "trigger_poor_sleep                  -0.8820      0.046    -18.974      0.000      -0.973      -0.791\n",
      "trigger_stress                      -0.6487      0.043    -15.072      0.000      -0.733      -0.564\n",
      "sleep_duration_hours                 0.0247      0.016      1.507      0.132      -0.007       0.057\n",
      "sleep_duration_past_7_days          -0.0304      0.019     -1.635      0.102      -0.067       0.006\n",
      "age                                 -0.0010      0.001     -0.686      0.493      -0.004       0.002\n",
      "migraine_attacks_past7days           0.2171      0.010     21.678      0.000       0.197       0.237\n",
      "mean_migraine_duration_past7days    -0.0263      0.004     -6.309      0.000      -0.034      -0.018\n",
      "total_physical_activity              0.0026      0.001      4.166      0.000       0.001       0.004\n",
      "reported_anxiety                    -0.5107      0.056     -9.061      0.000      -0.621      -0.400\n",
      "reported_depression                 -1.0978      0.063    -17.513      0.000      -1.221      -0.975\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "X_train_balanced_const = sm.add_constant(X_train_balanced)\n",
    "\n",
    "# Fit the logistic regression model on the balanced data\n",
    "logit_model = sm.Logit(y_train_balanced, X_train_balanced_const).fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "print(logit_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 26, 'max_features': None, 'min_samples_leaf': 9, 'min_samples_split': 18}\n",
      "\n",
      "AUC Score: 0.5065\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2207  382]\n",
      " [ 250   42]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87      2589\n",
      "           1       0.10      0.14      0.12       292\n",
      "\n",
      "    accuracy                           0.78      2881\n",
      "   macro avg       0.50      0.50      0.50      2881\n",
      "weighted avg       0.82      0.78      0.80      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],  # Splitting criteria\n",
    "    'max_depth': randint(5, 50),  # Randomly sample tree depth between 5 and 50\n",
    "    'min_samples_split': randint(2, 20),  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': randint(1, 10),  # Minimum samples required in a leaf node\n",
    "    'max_features': [None, 'sqrt', 'log2']  # Number of features to consider for best split\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=dt_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,  # Number of random combinations to try\n",
    "    scoring='roc_auc',  # Evaluate based on AUC\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the best model on the balanced training set\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Calculate and display AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 267}\n",
      "\n",
      "AUC Score: 0.5392\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2377  212]\n",
      " [ 267   25]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2589\n",
      "           1       0.11      0.09      0.09       292\n",
      "\n",
      "    accuracy                           0.83      2881\n",
      "   macro avg       0.50      0.50      0.50      2881\n",
      "weighted avg       0.82      0.83      0.83      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 300),  # Randomly sample between 50 and 300 trees\n",
    "    'max_depth': [None, 10, 20, 30],  # Fixed choices for tree depth\n",
    "    'min_samples_split': randint(2, 11),  # Randomly sample between 2 and 10 for splitting\n",
    "    'min_samples_leaf': randint(1, 5),  # Randomly sample between 1 and 4 for leaf nodes\n",
    "    'max_features': ['sqrt', 'log2', None],  # Fixed options for max features\n",
    "    'bootstrap': [True, False]  # Fixed options for bootstrapping\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    scoring='roc_auc',  # Evaluate based on AUC\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the best model on the balanced training set\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Calculate and display AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "\n",
      "                             Feature  Importance\n",
      "7         migraine_attacks_past7days    0.263546\n",
      "8   mean_migraine_duration_past7days    0.149300\n",
      "6                                age    0.127175\n",
      "5         sleep_duration_past_7_days    0.119795\n",
      "4               sleep_duration_hours    0.116856\n",
      "9            total_physical_activity    0.096041\n",
      "2                 trigger_poor_sleep    0.032532\n",
      "3                     trigger_stress    0.029963\n",
      "11               reported_depression    0.025399\n",
      "10                  reported_anxiety    0.018856\n",
      "0     trigger_lack_physical_activity    0.015625\n",
      "1          trigger_physical_activity    0.004912\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances from the trained Random Forest model\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_balanced.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\\n\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best Hyperparameters: {'learning_rate': 0.268219174976903, 'max_depth': 9, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 186, 'subsample': 0.8454489914076949}\n",
      "\n",
      "AUC Score: 0.5312\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2380  209]\n",
      " [ 266   26]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2589\n",
      "           1       0.11      0.09      0.10       292\n",
      "\n",
      "    accuracy                           0.84      2881\n",
      "   macro avg       0.51      0.50      0.50      2881\n",
      "weighted avg       0.82      0.84      0.83      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 200),  # Number of boosting stages\n",
    "    'learning_rate': uniform(0.01, 0.3),  # Learning rate for boosting\n",
    "    'max_depth': randint(3, 10),  # Maximum depth of individual estimators\n",
    "    'min_samples_split': randint(2, 10),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 5),  # Minimum number of samples required to be a leaf node\n",
    "    'subsample': uniform(0.7, 0.3),  # Fraction of samples used for fitting each base learner\n",
    "    'max_features': ['sqrt', 'log2', None]  # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=gb_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,  # Number of random combinations to try\n",
    "    scoring='roc_auc',  # Evaluate based on AUC\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the best model on the balanced training set\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Calculate and display AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "\n",
      "                             Feature  Importance\n",
      "7         migraine_attacks_past7days    0.351541\n",
      "8   mean_migraine_duration_past7days    0.121052\n",
      "4               sleep_duration_hours    0.100585\n",
      "5         sleep_duration_past_7_days    0.097222\n",
      "6                                age    0.094280\n",
      "9            total_physical_activity    0.094027\n",
      "11               reported_depression    0.036398\n",
      "3                     trigger_stress    0.036379\n",
      "2                 trigger_poor_sleep    0.032581\n",
      "10                  reported_anxiety    0.017640\n",
      "0     trigger_lack_physical_activity    0.013222\n",
      "1          trigger_physical_activity    0.005073\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances from the trained Gradient boosting model\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_balanced.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\\n\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best Hyperparameters: {'metric': 'manhattan', 'n_neighbors': 6, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "AUC Score: 0.5362\n",
      "Confusion Matrix:\n",
      "[[1677  912]\n",
      " [ 171  121]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.65      0.76      2589\n",
      "           1       0.12      0.41      0.18       292\n",
      "\n",
      "    accuracy                           0.62      2881\n",
      "   macro avg       0.51      0.53      0.47      2881\n",
      "weighted avg       0.83      0.62      0.70      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'n_neighbors': randint(1, 50),  # Number of neighbors to test\n",
    "    'weights': ['uniform', 'distance'],  # Weighting strategies\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],  # Distance metrics\n",
    "    'p': randint(1, 3)  # distance parameter \n",
    "}\n",
    "\n",
    "# Initialize the K-Nearest Neighbors model\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=knn_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,  # Number of random combinations to try\n",
    "    scoring='roc_auc',  # Evaluate based on AUC\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the best model on the balanced training set\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Calculate and display AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom imblearn.over_sampling import SMOTE\\nfrom scikeras.wrappers import KerasClassifier\\nimport numpy as np\\n\\n# Define features and target\\nfeatures = [\\'trigger_lack_physical_activity\\',\\'trigger_physical_activity\\',\\'trigger_poor_sleep\\',\\'trigger_stress\\',\\'sleep_duration_hours\\',\\'sleep_duration_past_7_days\\',\\'age\\',\\'migraine_attacks_past7days\\',\\'mean_migraine_duration_past7days\\',\\'total_physical_activity\\',\\'reported_anxiety\\', \\'reported_depression\\']\\n\\nX = df[features]\\ny = df[\\'affected_activity_QoL\\']\\n\\n# Split data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\\n\\n# Apply SMOTE to the training set\\nsmote = SMOTE(random_state=42)\\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\\n\\n# Scale the features\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train_smote)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Define a function to create the model\\ndef create_model(learning_rate=0.001, neurons=[64, 32, 16]):\\n    model = Sequential()\\n    model.add(Dense(neurons[0], activation=\\'relu\\', input_shape=(X_train_scaled.shape[1],)))\\n    model.add(Dense(neurons[1], activation=\\'relu\\'))\\n    model.add(Dense(neurons[2], activation=\\'relu\\'))\\n    model.add(Dense(1, activation=\\'sigmoid\\'))  # Binary classification\\n    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\\'binary_crossentropy\\', metrics=[\\'accuracy\\'])\\n    return model\\n\\n# Wrap the model for compatibility with RandomizedSearchCV\\nkeras_clf = KerasClassifier(model=create_model, verbose=0)\\n\\n# Define hyperparameter distributions\\nparam_distributions = {\\n    \"model__learning_rate\": [0.001, 0.01, 0.1],\\n    \"model__neurons\": [[64, 32, 16], [128, 64, 32], [32, 16, 8]],\\n    \"batch_size\": [16, 32, 64],\\n    \"epochs\": [20, 50, 100]\\n}\\n\\n# Set up RandomizedSearchCV\\nrandom_search = RandomizedSearchCV(\\n    estimator=keras_clf,\\n    param_distributions=param_distributions,\\n    n_iter=10,  # Number of random combinations to try\\n    scoring=\\'roc_auc\\',  # Focus on auc for hyperparameter tuning\\n    cv=3,  # 3-fold cross-validation\\n    verbose=1,\\n    n_jobs=-1,  # Use all available cores\\n    random_state=42\\n)\\n\\n# Perform hyperparameter tuning\\nrandom_search.fit(X_train_scaled, y_train_smote)\\n\\n# Get the best model and parameters\\nbest_model = random_search.best_estimator_\\nprint(\"Best Hyperparameters:\", random_search.best_params_)\\n\\n# Evaluate the model on the test set\\ny_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]  # Probabilities for the positive class\\ny_pred_classes = (y_pred_proba > 0.5).astype(int)  # Convert probabilities to binary classes\\n\\n# Calculate AUC\\nauc_score = roc_auc_score(y_test, y_pred_proba)\\nprint(f\"\\nAUC Score: {auc_score:.4f}\")\\n\\n# Confusion Matrix and Classification Report\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred_classes))\\nprint(\"\\nClassification Report:\")\\nprint(classification_report(y_test, y_pred_classes))\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define features and target\n",
    "features = ['trigger_lack_physical_activity','trigger_physical_activity','trigger_poor_sleep','trigger_stress','sleep_duration_hours','sleep_duration_past_7_days','age','migraine_attacks_past7days','mean_migraine_duration_past7days','total_physical_activity','reported_anxiety', 'reported_depression']\n",
    "target = 'next_migraine_next_day'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a function to create the model\n",
    "def create_model(learning_rate=0.001, neurons=[64, 32, 16]):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons[0], activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons[1], activation='relu'))\n",
    "    model.add(Dense(neurons[2], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the model for compatibility with RandomizedSearchCV\n",
    "keras_clf = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "# Define hyperparameter distributions\n",
    "param_distributions = {\n",
    "    \"model__learning_rate\": [0.001, 0.01, 0.1],\n",
    "    \"model__neurons\": [[64, 32, 16], [128, 64, 32], [32, 16, 8]],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [20, 50, 100]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=keras_clf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,  # Number of random combinations to try\n",
    "    scoring='roc_auc',  # Focus on auc for hyperparameter tuning\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "random_search.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]  # Probabilities for the positive class\n",
    "y_pred_classes = (y_pred_proba > 0.5).astype(int)  # Convert probabilities to binary classes\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_classes))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RESULTS\n",
    "Best Hyperparameters: {'model__neurons': [128, 64, 32], 'model__learning_rate': 0.001, 'epochs': 50, 'batch_size': 16}\n",
    "\n",
    "AUC Score: 0.5314\n",
    "Confusion Matrix:\n",
    "[[2020  569]\n",
    " [ 218   74]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.78      0.84      2589\n",
    "           1       0.12      0.25      0.16       292\n",
    "\n",
    "    accuracy                           0.73      2881\n",
    "   macro avg       0.51      0.52      0.50      2881\n",
    "weighted avg       0.82      0.73      0.77      2881"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
