{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, classification_report,mean_squared_error, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the dataset which comes from short_dataset_feature_engineering.ipynb \n",
    "file_path = '/data/caysar9/results/final_short.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency counts for each duration class before sampling:\n",
      "duration_in_hours\n",
      "Low       7409\n",
      "Medium    6842\n",
      "High       151\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frequency counts before SMOTE:\n",
      "Training set:\n",
      "duration_in_hours\n",
      "Low       5927\n",
      "Medium    5473\n",
      "High       121\n",
      "Name: count, dtype: int64\n",
      "Test set:\n",
      "duration_in_hours\n",
      "Low       1482\n",
      "Medium    1369\n",
      "High        30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frequency counts after SMOTE:\n",
      "duration_in_hours\n",
      "Low       5927\n",
      "Medium    5927\n",
      "High      5927\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define features and target \n",
    "features = ['trigger_lack_physical_activity','trigger_physical_activity','trigger_poor_sleep','trigger_stress','sleep_duration_hours','sleep_duration_past_7_days','age','migraine_attacks_past7days','mean_migraine_duration_past7days','total_physical_activity','reported_anxiety', 'reported_depression']\n",
    "\n",
    "\n",
    "target = 'duration_in_hours'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Define bins for migraine duration (Low: 4-9, Medium: 10-22, High: 23-72 hours)\n",
    "bins = [4, 9, 22, 72]\n",
    "labels = ['Low', 'Medium', 'High']  # Descriptive labels for Low, Medium, High\n",
    "y_binned = pd.cut(y, bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Frequency counts\n",
    "print(\"Frequency counts for each duration class before sampling:\")\n",
    "print(y_binned.value_counts())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binned, test_size=0.2, random_state=42, stratify=y_binned)\n",
    "\n",
    "# Frequency counts before applying SMOTE\n",
    "print(\"\\nFrequency counts before SMOTE:\")\n",
    "print(\"Training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"Test set:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Frequency counts after applying SMOTE\n",
    "print(\"\\nFrequency counts after SMOTE:\")\n",
    "print(y_train_balanced.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 6.184815096277165, 'max_iter': 413, 'multi_class': 'multinomial', 'solver': 'newton-cg'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/caysar9/venv-py311/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC Score (One-vs-One): 0.9178\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  22    0    8]\n",
      " [  26 1308  148]\n",
      " [ 176  225  968]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.10      0.73      0.17        30\n",
      "      Medium       0.85      0.88      0.87      1482\n",
      "        High       0.86      0.71      0.78      1369\n",
      "\n",
      "    accuracy                           0.80      2881\n",
      "   macro avg       0.60      0.77      0.61      2881\n",
      "weighted avg       0.85      0.80      0.82      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'C': uniform(0.01, 10),  # Regularization strength\n",
    "    'max_iter': randint(100, 1000),  # Number of iterations\n",
    "    'solver': ['lbfgs', 'newton-cg', 'sag'],  # Solvers that support multinomial\n",
    "    'multi_class': ['multinomial']  # Multinomial setting for multi-class classification\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    scoring='roc_auc_ovo',  # Optimize based on AUC (One-vs-One for multi-class)\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the best model on the balanced training set\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)  # Probabilities for each class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovo')\n",
    "print(f\"\\nAUC Score (One-vs-One): {auc_score:.4f}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Low\", \"Medium\", \"High\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.416807\n",
      "         Iterations 9\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:      duration_in_hours   No. Observations:                17781\n",
      "Model:                        MNLogit   Df Residuals:                    17755\n",
      "Method:                           MLE   Df Model:                           24\n",
      "Date:                Sat, 07 Dec 2024   Pseudo R-squ.:                  0.6206\n",
      "Time:                        18:55:27   Log-Likelihood:                -7411.3\n",
      "converged:                       True   LL-Null:                       -19534.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "====================================================================================================\n",
      "        duration_in_hours=Medium       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "const                               -7.8481      0.218    -36.045      0.000      -8.275      -7.421\n",
      "trigger_lack_physical_activity      -0.1792      0.109     -1.650      0.099      -0.392       0.034\n",
      "trigger_physical_activity           -0.1600      0.217     -0.736      0.461      -0.586       0.266\n",
      "trigger_poor_sleep                   0.0100      0.071      0.141      0.888      -0.129       0.149\n",
      "trigger_stress                       0.0278      0.073      0.382      0.702      -0.115       0.170\n",
      "sleep_duration_hours                -0.0238      0.027     -0.875      0.381      -0.077       0.030\n",
      "sleep_duration_past_7_days           0.0147      0.031      0.474      0.636      -0.046       0.076\n",
      "age                                 -0.0032      0.003     -1.225      0.221      -0.008       0.002\n",
      "migraine_attacks_past7days          -0.1606      0.018     -8.699      0.000      -0.197      -0.124\n",
      "mean_migraine_duration_past7days     0.8803      0.016     55.322      0.000       0.849       0.911\n",
      "total_physical_activity              0.0001      0.001      0.119      0.905      -0.002       0.002\n",
      "reported_anxiety                     0.1244      0.086      1.440      0.150      -0.045       0.294\n",
      "reported_depression                  0.0305      0.082      0.370      0.711      -0.131       0.192\n",
      "----------------------------------------------------------------------------------------------------\n",
      "          duration_in_hours=High       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "const                              -18.8470      0.346    -54.505      0.000     -19.525     -18.169\n",
      "trigger_lack_physical_activity      -2.0884      0.275     -7.595      0.000      -2.627      -1.549\n",
      "trigger_physical_activity           -3.8296      0.805     -4.759      0.000      -5.407      -2.253\n",
      "trigger_poor_sleep                  -1.3011      0.123    -10.606      0.000      -1.542      -1.061\n",
      "trigger_stress                      -1.4016      0.118    -11.871      0.000      -1.633      -1.170\n",
      "sleep_duration_hours                -0.0346      0.036     -0.975      0.329      -0.104       0.035\n",
      "sleep_duration_past_7_days          -0.0336      0.041     -0.823      0.410      -0.113       0.046\n",
      "age                                 -0.0287      0.004     -7.577      0.000      -0.036      -0.021\n",
      "migraine_attacks_past7days           0.8454      0.031     27.424      0.000       0.785       0.906\n",
      "mean_migraine_duration_past7days     1.5575      0.021     75.061      0.000       1.517       1.598\n",
      "total_physical_activity              0.0025      0.002      1.453      0.146      -0.001       0.006\n",
      "reported_anxiety                    -0.6095      0.140     -4.351      0.000      -0.884      -0.335\n",
      "reported_depression                 -1.1248      0.144     -7.788      0.000      -1.408      -0.842\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Add a constant to the feature set for the intercept term\n",
    "X_train_balanced_const = sm.add_constant(X_train_balanced)\n",
    "\n",
    "\n",
    "# Fit a multinomial logistic regression model using statsmodels\n",
    "logit_model = sm.MNLogit(y_train_balanced, X_train_balanced_const)\n",
    "logit_results = logit_model.fit()\n",
    "\n",
    "# Get the summary, including coefficients and p-values\n",
    "print(logit_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Hyperparameters: {'criterion': 'log_loss', 'max_depth': 9, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 16}\n",
      "\n",
      "AUC Score (One-vs-One): 0.9471\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  23    0    7]\n",
      " [  17 1276  189]\n",
      " [ 111  169 1089]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.15      0.77      0.25        30\n",
      "      Medium       0.88      0.86      0.87      1482\n",
      "        High       0.85      0.80      0.82      1369\n",
      "\n",
      "    accuracy                           0.83      2881\n",
      "   macro avg       0.63      0.81      0.65      2881\n",
      "weighted avg       0.86      0.83      0.84      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],  # Splitting criteria\n",
    "    'max_depth': randint(3, 50),  # Maximum depth of the tree\n",
    "    'min_samples_split': randint(2, 20),  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': randint(1, 10),  # Minimum number of samples in a leaf node\n",
    "    'max_features': [None, 'sqrt', 'log2']  # Number of features considered for the best split\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=dt_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    scoring='roc_auc_ovo',  # Evaluate based on AUC for multi-class problems\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the best model on the balanced training set\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)  # Probabilities for each class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovo')\n",
    "print(f\"\\nAUC Score (One-vs-One): {auc_score:.4f}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Low\", \"Medium\", \"High\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': 34, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 253}\n",
      "\n",
      "AUC Score (One-vs-One): 0.9456\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  18    0   12]\n",
      " [   2 1271  209]\n",
      " [  13  180 1176]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.55      0.60      0.57        30\n",
      "      Medium       0.88      0.86      0.87      1482\n",
      "        High       0.84      0.86      0.85      1369\n",
      "\n",
      "    accuracy                           0.86      2881\n",
      "   macro avg       0.75      0.77      0.76      2881\n",
      "weighted avg       0.86      0.86      0.86      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 300),  # Number of trees in the forest\n",
    "    'max_depth': randint(5, 50),  # Maximum depth of each tree\n",
    "    'min_samples_split': randint(2, 20),  # Minimum samples to split a node\n",
    "    'min_samples_leaf': randint(1, 10),  # Minimum samples in a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None],  # Number of features to consider for the best split\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    scoring='roc_auc_ovo',  # Evaluate based on AUC for multi-class classification\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the best model on the balanced training set\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)  # Probabilities for each class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovo')\n",
    "print(f\"\\nAUC Score (One-vs-One): {auc_score:.4f}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Low\", \"Medium\", \"High\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "                              Feature  Importance\n",
      "8   mean_migraine_duration_past7days    0.638196\n",
      "7         migraine_attacks_past7days    0.116861\n",
      "9            total_physical_activity    0.046713\n",
      "6                                age    0.046062\n",
      "5         sleep_duration_past_7_days    0.045474\n",
      "4               sleep_duration_hours    0.042734\n",
      "3                     trigger_stress    0.020322\n",
      "2                 trigger_poor_sleep    0.019292\n",
      "10                  reported_anxiety    0.010634\n",
      "11               reported_depression    0.007725\n",
      "0     trigger_lack_physical_activity    0.004765\n",
      "1          trigger_physical_activity    0.001224\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "feature_names = X_train_balanced.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\\n\", importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.06597101766581075, 'max_depth': 13, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 8, 'n_estimators': 239, 'subsample': 0.733015577358303}\n",
      "\n",
      "AUC Score (One-vs-One): 0.9474\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  18    0   12]\n",
      " [   1 1288  193]\n",
      " [   9  193 1167]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.64      0.60      0.62        30\n",
      "      Medium       0.87      0.87      0.87      1482\n",
      "        High       0.85      0.85      0.85      1369\n",
      "\n",
      "    accuracy                           0.86      2881\n",
      "   macro avg       0.79      0.77      0.78      2881\n",
      "weighted avg       0.86      0.86      0.86      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 300),  # Number of boosting stages\n",
    "    'learning_rate': uniform(0.01, 0.3),  # Learning rate for boosting\n",
    "    'max_depth': randint(3, 20),  # Maximum depth of each tree\n",
    "    'min_samples_split': randint(2, 20),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 10),  # Minimum number of samples required in a leaf node\n",
    "    'subsample': uniform(0.7, 0.3),  # Fraction of samples used for fitting each base learner\n",
    "    'max_features': ['sqrt', 'log2', None]  # Number of features to consider for splits\n",
    "}\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=gb_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    scoring='roc_auc_ovo',  # Evaluate based on AUC for multi-class classification\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the best model on the balanced training set\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)  # Probabilities for each class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovo')\n",
    "print(f\"\\nAUC Score (One-vs-One): {auc_score:.4f}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Low\", \"Medium\", \"High\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "                              Feature  Importance\n",
      "8   mean_migraine_duration_past7days    0.657411\n",
      "7         migraine_attacks_past7days    0.116229\n",
      "5         sleep_duration_past_7_days    0.046590\n",
      "4               sleep_duration_hours    0.045678\n",
      "6                                age    0.041423\n",
      "9            total_physical_activity    0.040494\n",
      "3                     trigger_stress    0.017699\n",
      "2                 trigger_poor_sleep    0.016416\n",
      "10                  reported_anxiety    0.008766\n",
      "11               reported_depression    0.005562\n",
      "0     trigger_lack_physical_activity    0.002885\n",
      "1          trigger_physical_activity    0.000846\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "feature_names = X_train_balanced.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\\n\", importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Hyperparameters: {'metric': 'minkowski', 'n_neighbors': 22, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "AUC Score (One-vs-One): 0.9193\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  23    0    7]\n",
      " [  23 1282  177]\n",
      " [ 162  223  984]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.11      0.77      0.19        30\n",
      "      Medium       0.85      0.87      0.86      1482\n",
      "        High       0.84      0.72      0.78      1369\n",
      "\n",
      "    accuracy                           0.79      2881\n",
      "   macro avg       0.60      0.78      0.61      2881\n",
      "weighted avg       0.84      0.79      0.81      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'n_neighbors': randint(1, 50),  # Number of neighbors\n",
    "    'weights': ['uniform', 'distance'],  # Weighting strategies\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],  # Distance metrics\n",
    "    'p': randint(1, 3)  # distance parameter \n",
    "}\n",
    "\n",
    "# Initialize the K-Nearest Neighbors model\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=knn_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    scoring='roc_auc_ovo',  # Evaluate based on AUC for multi-class classification\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the best model on the balanced training set\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)  # Probabilities for each class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovo')\n",
    "print(f\"\\nAUC Score (One-vs-One): {auc_score:.4f}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Low\", \"Medium\", \"High\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nfrom scikeras.wrappers import KerasClassifier\\nfrom imblearn.over_sampling import SMOTE\\nfrom sklearn.preprocessing import StandardScaler\\nimport numpy as np\\n\\n# Define features and target\\nfeatures = [\\'trigger_lack_physical_activity\\',\\'trigger_physical_activity\\',\\'trigger_poor_sleep\\',\\'trigger_stress\\',\\'sleep_duration_hours\\',\\'sleep_duration_past_7_days\\',\\'age\\',\\'migraine_attacks_past7days\\',\\'mean_migraine_duration_past7days\\',\\'total_physical_activity\\',\\'reported_anxiety\\', \\'reported_depression\\']\\n\\ntarget = \\'attack_duration_hours\\'\\n\\nX = df[features]\\ny = df[target]\\n\\n# Define bins for migraine duration (Low: 4-9, Medium: 10-22, High: 23-72 hours)\\nbins = [4, 9, 22, 72]\\ny_binned = np.digitize(y, bins=bins, right=True)\\ny_binned = np.clip(y_binned, 1, 3) \\ny_encoded = y_binned - 1  # Map to [0, 1, 2]\\n\\n# Split data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\\n\\n# Apply SMOTE to the training set\\nsmote = SMOTE(random_state=42)\\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\\n\\n# Scale the features\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train_smote)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Define a function to create the neural network model\\ndef create_model(learning_rate=0.001, neurons=[64, 32, 16]):\\n    model = Sequential()\\n    model.add(Dense(neurons[0], activation=\\'relu\\', input_shape=(X_train_scaled.shape[1],)))\\n    model.add(Dense(neurons[1], activation=\\'relu\\'))\\n    model.add(Dense(neurons[2], activation=\\'relu\\'))\\n    model.add(Dense(3, activation=\\'softmax\\'))  # 3 classes: Low, Medium, High\\n    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\\'sparse_categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n    return model\\n\\n# Wrap the model for RandomizedSearchCV\\nkeras_clf = KerasClassifier(model=create_model, verbose=0)\\n\\n# Define hyperparameter distributions\\nparam_distributions = {\\n    \"model__learning_rate\": [0.001, 0.01, 0.1],\\n    \"model__neurons\": [[64, 32, 16], [128, 64, 32], [32, 16, 8]],\\n    \"batch_size\": [16, 32, 64],\\n    \"epochs\": [20, 50, 100]\\n}\\n\\n# Set up RandomizedSearchCV\\nrandom_search = RandomizedSearchCV(\\n    estimator=keras_clf,\\n    param_distributions=param_distributions,\\n    n_iter=10,  # Number of random combinations to try\\n    scoring=\\'roc_auc_ovo\\',  # Optimize AUC for multi-class classification\\n    cv=3,  # 3-fold cross-validation\\n    verbose=1,\\n    n_jobs=-1,  # Use all available cores\\n    random_state=42\\n)\\n\\n# Fit RandomizedSearchCV to the training data\\nrandom_search.fit(X_train_scaled, y_train_smote)\\n\\n# Get the best model and parameters\\nbest_model = random_search.best_estimator_\\nprint(\"Best Hyperparameters:\", random_search.best_params_)\\n\\n# Evaluate the model\\ny_pred = best_model.predict(X_test_scaled)\\ny_pred_proba = best_model.predict_proba(X_test_scaled)\\n\\n# Calculate AUC\\nauc_score = roc_auc_score(y_test, y_pred_proba, multi_class=\\'ovo\\')\\nprint(f\"\\nAUC Score (One-vs-One): {auc_score:.4f}\")\\n\\n# Confusion Matrix and Classification Report\\ny_pred_classes = y_pred.argmax(axis=1)\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred_classes))\\nprint(\"\\nClassification Report:\")\\nprint(classification_report(y_test, y_pred_classes, target_names=[\"Low\", \"Medium\", \"High\"]))\\n\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''DNN:\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Define features and target\n",
    "features = ['trigger_lack_physical_activity','trigger_physical_activity','trigger_poor_sleep','trigger_stress','sleep_duration_hours','sleep_duration_past_7_days','age','migraine_attacks_past7days','mean_migraine_duration_past7days','total_physical_activity','reported_anxiety', 'reported_depression']\n",
    "\n",
    "\n",
    "target = 'duration_in_hours'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Define bins for migraine duration (Low: 4-9, Medium: 10-22, High: 23-72 hours)\n",
    "bins = [4, 9, 22, 72]\n",
    "y_binned = np.digitize(y, bins=bins, right=True)\n",
    "y_binned = np.clip(y_binned, 1, 3) \n",
    "y_encoded = y_binned - 1  # Map to [0, 1, 2]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a function to create the neural network model\n",
    "def create_model(learning_rate=0.001, neurons=[64, 32, 16]):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons[0], activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons[1], activation='relu'))\n",
    "    model.add(Dense(neurons[2], activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))  # 3 classes: Low, Medium, High\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the model for RandomizedSearchCV\n",
    "keras_clf = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "# Define hyperparameter distributions\n",
    "param_distributions = {\n",
    "    \"model__learning_rate\": [0.001, 0.01, 0.1],\n",
    "    \"model__neurons\": [[64, 32, 16], [128, 64, 32], [32, 16, 8]],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [20, 50, 100]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=keras_clf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,  # Number of random combinations to try\n",
    "    scoring='roc_auc_ovo',  # Optimize AUC for multi-class classification\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovo')\n",
    "print(f\"\\nAUC Score (One-vs-One): {auc_score:.4f}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "y_pred_classes = y_pred  \n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_classes))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=[\"Low\", \"Medium\", \"High\"]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RESULTS:\n",
    "\n",
    "Best Hyperparameters: {'model__neurons': [64, 32, 16], 'model__learning_rate': 0.001, 'epochs': 20, 'batch_size': 16}\n",
    "\n",
    "AUC Score (One-vs-One): 0.9152\n",
    "Confusion Matrix:\n",
    "[[1288  190    4]\n",
    " [ 203 1101   65]\n",
    " [   0   17   13]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         Low       0.86      0.87      0.87      1482\n",
    "      Medium       0.84      0.80      0.82      1369\n",
    "        High       0.16      0.43      0.23        30\n",
    "\n",
    "    accuracy                           0.83      2881\n",
    "   macro avg       0.62      0.70      0.64      2881\n",
    "weighted avg       0.85      0.83      0.84      2881"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
